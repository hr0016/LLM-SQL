{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b950eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitsandbytes accelerate sqlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a6a3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<socket.socket fd=440, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.32.115', 59425), raddr=('192.168.32.93', 1234)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import socket, requests\n",
    "socket.socket(socket.AF_INET, socket.SOCK_STREAM).settimeout(2)\n",
    "socket.create_connection(('192.168.32.93', 1234), timeout=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8680e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch,transformers,bitsandbytes,accelerate,sqlparse\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "752929af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-interactive model version\n",
    "\n",
    "def llm_sql_QnA(user_question):\n",
    "    # the prompt\n",
    "    prompt = \"\"\"\n",
    "    # Task\n",
    "    Generate a SQL query to answer the following question:\n",
    "    `{question}`\n",
    "\n",
    "    # Database Schema\n",
    "    The query will run on a database with the following schema:\n",
    "    \n",
    "    CREATE TABLE result_both_models (\n",
    "    mpan\n",
    "    read_date\n",
    "    next_read_date\n",
    "    sum_dpc\n",
    "    current_eac\n",
    "    ind_cal_eac\n",
    "    ml_cal_eac \n",
    "    );\n",
    "\n",
    "    CREATE TABLE result_cal_eac (\n",
    "    mpan\n",
    "    read_date\n",
    "    next_read_date\n",
    "    sum_dpc\n",
    "    previous_eac\n",
    "    current_eac\n",
    "    );\n",
    "\n",
    "    ### ADDITIONAL NOTES\n",
    "    --you are using Presto/Trio as the SQL engine \n",
    "    --the column \"ind_cal_eac\" means EAC calculated using the industry provided method\n",
    "    --the column \"ml_cal_eac\" means EAC obtained from the machine learnig (ML) model\n",
    "    \n",
    "    ### FEEDBACK ON TOP OF YOUR ANSWERS, PLEASE CONSIDER THEM AND UPDATE YOUR ANSWER ACCORDINGLY IF PROVIDED\n",
    "    --`{feedback}` \n",
    "\n",
    "    ### SQL \n",
    "    Given the database schema, here is the SQL query that answers `{question}`:\n",
    "    ```sql\n",
    "    \"\"\".format(question=user_question, feedback=user_feedback)\n",
    "    \n",
    "    payload = {\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "    \n",
    "    url = \"http://192.168.32.93:1234/v1/completions\"\n",
    "    \n",
    "    response = requests.post(url=url, json = payload)\n",
    "    \n",
    "    llm_answer = response.json()[\"choices\"][0][\"text\"]\n",
    "    \n",
    "    return print(\"Question: {} \\n\\nLLM answer: {}\".format(user_question, llm_answer))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f92be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive model version\n",
    "\n",
    "class llm_sql:\n",
    "    \n",
    "    def __init__(self, question, schema, notes):\n",
    "        self.question = question\n",
    "        self.schema = schema\n",
    "        self.notes = notes\n",
    "        self.feedback = \"\"\n",
    "        self.prompt = \"\"\"\n",
    "        # Task\n",
    "        Generate a SQL query to answer the following question:\n",
    "        `{question}`\n",
    "\n",
    "        # Database Schema\n",
    "        The query will run on a database with the following schema:\n",
    "        `{schema}`\n",
    "\n",
    "        ### ADDITIONAL NOTES\n",
    "        `{notes}`\n",
    "\n",
    "        ### FEEDBACK ON TOP OF YOUR ANSWERS, PLEASE CONSIDER THEM AND IMPROVE YOUR ANSWER IF PROVIDED\n",
    "        --{feedback} \n",
    "\n",
    "        ### SQL \n",
    "        Given the database schema, here is the SQL query that answers `{question}`:\n",
    "        ```sql\n",
    "        \"\"\".format(question = self.question, schema = self.schema, notes = self.notes, feedback = self.feedback) \n",
    "\n",
    "    def get_question(self, question):\n",
    "        self.question = question\n",
    " \n",
    "    def get_feedback(self, llm_answer, feedback):\n",
    "        self.feedback += \"\\n--The solution `{}` \".format(llm_answer) + \"has the feedback `{}`.\".format(feedback)\n",
    "        \n",
    "    def get_response(self, question):\n",
    "        payload = {\n",
    "            \"prompt\": self.prompt\n",
    "        }\n",
    "        url = \"http://192.168.32.93:1234/v1/completions\"\n",
    "        response = requests.post(url=url, json = payload)\n",
    "        llm_answer = response.json()[\"choices\"][0][\"text\"]\n",
    "        print(\"LLM Answer: {}\".format(llm_answer))\n",
    "        return llm_answer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f33dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing schema of two tables from AWS Synthetic EAC testing environment \n",
    "\n",
    "schema1 =\"\"\" \n",
    "CREATE TABLE result_both_models (\n",
    "mpan\n",
    "read_date\n",
    "next_read_date\n",
    "sum_dpc\n",
    "current_eac\n",
    "ind_cal_eac\n",
    "ml_cal_eac \n",
    ");\n",
    "\n",
    "CREATE TABLE result_cal_eac (\n",
    "mpan\n",
    "read_date\n",
    "next_read_date\n",
    "sum_dpc\n",
    "previous_eac\n",
    "current_eac\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "notes1 = \"\"\"\n",
    "--you are using Presto/Trio as the SQL engine, please only respond using Presto/Trio format\n",
    "--the column \"ind_cal_eac\" means EAC calculated using the industry provided method\n",
    "--the column \"ml_cal_eac\" means EAC obtained from the machine learnig (ML) model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f003965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question1 = \"How many distinct MPANs are there in both datasets?\"\n",
    "user_question2 = \"What are the MPAN with industry calculated EAC volume larger than 100 between the period of 2023-06 and 2023-08?\"\n",
    "user_question3 = \"What are the average volume of previous EAC for all MPAN records from February 2023 till now?\"\n",
    "user_question4 = \"Can you show me the percentage of records that have any missing values in the previous EAC column?\"\n",
    "user_question5 = \"Can you show the percentage of records that have an ML EAC with less than 10% absolute-percentage-error compared to current EAC?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c85a161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on schema of two tables from Empris staging environment  \n",
    "\n",
    "schema2 =\"\"\" \n",
    "CREATE TABLE HH_data (\n",
    "mpan  --type: bigint\n",
    "supplier_id  --type: string\n",
    "settlement_date  --type: date\n",
    "settlement_period  --type: int\n",
    "measurement_qty_id  --type: string\n",
    "actual_estimated_indicator  --type: string  \n",
    "volume  --type: decimal \n",
    ");\n",
    "\n",
    "CREATE TABLE smart_meter_installs (\n",
    "mpan  --type: bigint\n",
    "install_date  --type: date\n",
    "meter_type_group  --type: string\n",
    "postcode_area  --type: string\n",
    "postcode_sector  --type: string\n",
    "postcode_district  --type: string\n",
    "postcode  --type: string\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "notes2 = \"\"\"\n",
    "--you are using Presto/Trio as the SQL engine, please only respond using Presto/Trio format\n",
    "--HH means Half-Hourly\n",
    "--the granuality order from macro to micro is: postcode_area > postcode_district > postcode_sector > postcode  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question1 = \"How many different mpans are there that do not have any missing volume record?\"\n",
    "user_question2 = \"How many meters are installed in January and Feburary of 2023?\"\n",
    "user_question3 = \"How many meters are installed in the post code area of MK1 in 2023?\"\n",
    "user_question4 = \"Show me a list of postcode where there's a total count of less than 100 meter installs in 2024\"\n",
    "user_question5 = 'What is the average HH volume for mpans in the postcode MK1 that have meter type group as \"SMETS2\"?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1c0e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask question of the database to generate SQL query: \n",
      "How many different mpans are there that do not have any missing volume record?\n",
      "\n",
      "\n",
      "LLM Answer: SELECT COUNT(DISTINCT mpan) AS number_of_mpans FROM HH_data WHERE volume IS NOT NULL;\n",
      "Does the query look good? (Y/N) \n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #schema = schema1\n",
    "    #notes = notes1\n",
    "    schema = schema2\n",
    "    notes = schema2\n",
    "    question = input(\"ask question of the database to generate SQL query: \\n\")\n",
    "    print(\"\\n\")\n",
    "    llm_sql1 = llm_sql(question, schema, notes)\n",
    "    #llm_sql1.get_question(question)\n",
    "    llm_answer = llm_sql1.get_response(question)\n",
    "    while True:\n",
    "        feedback = input(\"Does the query look good? (Y/N) \\n\")\n",
    "        if feedback in [\"Y\"]:\n",
    "            break\n",
    "        elif feedback in [\"N\"]:\n",
    "            feedback = input(\"Please advise to improve: \\n\")\n",
    "            print(\"\\n\")\n",
    "            llm_sql1.get_feedback(llm_answer, feedback)\n",
    "            llm_answer = llm_sql1.get_response(question) \n",
    "        else:\n",
    "            raise ValueError('Y or N?')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c0702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07247c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72938025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89fedd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(r'C:\\Users\\Hang.Ruan\\Downloads\\metadata.json')\n",
    "metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a4b2d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'name', 'db_name', 'database', 'organisation_id', 'user_id', 'number_of_rows', 'last_data_update', 'columns'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2875d01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'name', 'display_name', 'sample', 'type', 'values', 'description', 'pii', 'taxonomy'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0]['columns'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e07810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 220,\n",
       " 'name': 'pcd2',\n",
       " 'display_name': 'pcd2',\n",
       " 'sample': '',\n",
       " 'type': 'string',\n",
       " 'values': None,\n",
       " 'description': 'As above, except: 2, 3 or 4-character outward code - left aligned; 3-character inward code - right aligned; 5th character always blank and 3rd and 4th characters may be blank (?)',\n",
       " 'pii': False,\n",
       " 'taxonomy': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[0]['columns'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0c0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
